{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "files = os.listdir(path)\n",
    "\n",
    "data = ''\n",
    "\n",
    "# opening each file, converting data to lowercase and appending to data\n",
    "# for file in files:\n",
    "#     if os.path.isfile(os.path.join(path, file)):\n",
    "#         file_content = open(os.path.join(path, file), 'r', encoding='utf-8').read()\n",
    "#         data += file_content.lower()\n",
    "\n",
    "# opening single file\n",
    "file_content = open('data/drake.txt', 'r', encoding='utf-8').read()\n",
    "data += file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus: 199038\n",
      "[Hook]\n",
      "I've been down so long, it look like up to me\n",
      "They look up to me\n",
      "I got fake people showin' fake love to me\n",
      "Straight up to my face, straight up to my face\n",
      "I've been down so long, it look like up\n"
     ]
    }
   ],
   "source": [
    "print('Length of corpus:', len(data))\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters before: 82\n",
      "Number of unique characters after: 80\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique characters before:', len(set(data)))\n",
    "\n",
    "# Replace all non ascii characters in data with ''\n",
    "data = re.sub(r'[^\\x00-\\x7F]', r'', data)\n",
    "print('Number of unique characters after:', len(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 80\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(data))\n",
    "print('Total chars:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 66332\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(data) - maxlen, step):\n",
    "    sentences.append(data[i: i + maxlen])\n",
    "    next_chars.append(data[i + maxlen])\n",
    "\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
    "for i, sent in enumerate(sentences):\n",
    "    for t, char in enumerate(sent):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               107008    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                10320     \n",
      "=================================================================\n",
      "Total params: 117,328\n",
      "Trainable params: 117,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape = (maxlen, len(chars))),\n",
    "    LSTM(units = 128, activation = 'relu'),\n",
    "    Dense(units = len(chars), activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate = 1e-3, decay = 1e-5)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519/519 [==============================] - 66s 122ms/step - loss: 1.5942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed44b1b670>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(x, y, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: \"e bills fall\n",
      "All over your skin\n",
      "I got mo\"\n",
      "se, up treaty every dight me time\n",
      "On, I take ain't gettin' it and Cnuls I do raid a bourn Cing,\n",
      "All it's me pot Bhuse troud yeah the yough the so, that up, it\n",
      "I amand yeah, I say forttorsing But and it roop\n",
      "I'm on bright me, all may when you the Mamed my dippin' Mance\n",
      "Call, think noghtake, get of ah, drigo\n",
      "Now I ward wlo nigga got, ing\n",
      "Starty eight like you winke tell a with debe\n",
      "\n",
      "Cout used brubd \n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(data) - maxlen - 1)\n",
    "\n",
    "generated = \"\"\n",
    "sentence = data[start_index : start_index + maxlen]\n",
    "print('Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "for i in range(400):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.0\n",
    "        \n",
    "    preds = model.predict(x_pred)[0]\n",
    "\n",
    "    next_index = sample(preds)\n",
    "    next_char = indices_char[next_index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    generated += next_char\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

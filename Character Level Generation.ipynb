{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "data = ''\n",
    "\n",
    "# opening each file and appending to data\n",
    "# files = os.listdir(path)\n",
    "# for file in files:\n",
    "#     if os.path.isfile(os.path.join(path, file)):\n",
    "#         file_content = open(os.path.join(path, file), 'r', encoding='utf-8').read()\n",
    "#         data += file_content\n",
    "\n",
    "files = ['bieber', 'bruno-mars', 'drake', 'rihanna', 'adele']\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(path, file + '.txt')):\n",
    "        file_content = open(os.path.join(path, file + '.txt'), 'r', encoding='utf-8').read()\n",
    "        data += file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus: 711225\n",
      "What do you mean?\n",
      "Oh, oh, oh\n",
      "When you sometimes say yes\n",
      "But you sometimes say no\n",
      "What do you mean?\n",
      "Hey, yeah\n",
      "When you don't want me to move\n",
      "But you tell me to go\n",
      "What do you mean?\n",
      "Oh\n",
      "What do you mean?\n"
     ]
    }
   ],
   "source": [
    "print('Length of corpus:', len(data))\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters before: 90\n",
      "Number of unique characters after: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique characters before:', len(set(data)))\n",
    "\n",
    "# Replace all non ascii characters in data with ''\n",
    "data = re.sub(r'[^\\x00-\\x7F]', r'', data)\n",
    "print('Number of unique characters after:', len(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 82\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(data))\n",
    "print('Total chars:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 236991\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(data) - maxlen, step):\n",
    "    sentences.append(data[i: i + maxlen])\n",
    "    next_chars.append(data[i + maxlen])\n",
    "\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
    "for i, sent in enumerate(sentences):\n",
    "    for t, char in enumerate(sent):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               108032    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 82)                10578     \n",
      "=================================================================\n",
      "Total params: 118,610\n",
      "Trainable params: 118,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape = (maxlen, len(chars))),\n",
    "    LSTM(units = 128, activation = 'tanh'),\n",
    "    Dense(units = len(chars), activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate = 1e-3, decay = 1e-5)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1852/1852 [==============================] - 20s 11ms/step - loss: 0.7698\n",
      "Epoch 2/10\n",
      "1852/1852 [==============================] - 20s 11ms/step - loss: 0.7669\n",
      "Epoch 3/10\n",
      "1852/1852 [==============================] - 22s 12ms/step - loss: 0.7642\n",
      "Epoch 4/10\n",
      "1852/1852 [==============================] - 18s 10ms/step - loss: 0.7615\n",
      "Epoch 5/10\n",
      "1852/1852 [==============================] - 20s 11ms/step - loss: 0.7585\n",
      "Epoch 6/10\n",
      "1852/1852 [==============================] - 21s 11ms/step - loss: 0.7566\n",
      "Epoch 7/10\n",
      "1852/1852 [==============================] - 18s 10ms/step - loss: 0.7546\n",
      "Epoch 8/10\n",
      "1852/1852 [==============================] - 19s 10ms/step - loss: 0.7517\n",
      "Epoch 9/10\n",
      "1852/1852 [==============================] - 18s 10ms/step - loss: 0.7498\n",
      "Epoch 10/10\n",
      "1852/1852 [==============================] - 19s 10ms/step - loss: 0.7475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17674963ee0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(x, y, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: \"me by the hand while we do what lovers d\"\n",
      "o\n",
      "Sad it who styOn and searss in my own that it\n",
      " reah shot of how Amorias I'm a guing hon it time, fuck up a yJ Lete ginl, I'm me inger Best with you're right in the sad out ot ever, staring say, ham's much wonna have to fect\n",
      "Let me and werknwas in ferentless\n",
      "Trong usout\n",
      "This to tol me\n",
      "I know where you astan\n",
      "Cay you keep lostoping up and piace, yno thay myself she loselive me\n",
      "I sun the stude, has \n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(data) - maxlen - 1)\n",
    "\n",
    "generated = \"\"\n",
    "sentence = data[start_index : start_index + maxlen]\n",
    "print('Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "for i in range(400):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.0\n",
    "        \n",
    "    preds = model.predict(x_pred)[0]\n",
    "\n",
    "    next_index = sample(preds)\n",
    "    next_char = indices_char[next_index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    generated += next_char\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_100\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
